{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Use-case: Fish tracking"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Classical conditioning experiments of weakly electric fish *Apteronotus albifrons*\n",
      "\n",
      "-- Benda Lab, University of T\u00fcbingen, Germany --"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Context:**\n",
      "\n",
      " - Fish are trained to choose one electical stimulus.\n",
      " - Trials are videotaped @25Hz using an IR camera.\n",
      " - Fish are tracked, position and orientation extracted. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nix\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "from utils.notebook import print_stats\n",
      "from utils.video_player import Playback\n",
      "\n",
      "nix_file = nix.File.open('data/tracking_data.h5', nix.FileMode.ReadOnly)\n",
      "print_stats(nix_file.blocks)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Blocks                                             (01)\n",
        "\ttype: recording                            (01)\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "b = nix_file.blocks[0]\n",
      "print_stats(b.data_arrays)\n",
      "print_stats(b.multi_tags)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "DataArrays                                         (06)\n",
        "\ttype: nix.stamped_video                    (01)\n",
        "\ttype: nix.tracking.orientation             (01)\n",
        "\ttype: nix.event.positions                  (02)\n",
        "\ttype: nix.event.extents                    (02)\n",
        "\n",
        "MultiTags                                          (02)\n",
        "\ttype: nix.event                            (02)\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Storing of video data:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Movies are, depending on the number of color channels, stored as 3D, respectively 4D **DataArrays**."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "video = [a for a in b.data_arrays if a.name == \"video\"][0]\n",
      "\n",
      "fig = plt.figure(facecolor='white', figsize=(1024 / 90, 768 / 90), dpi=90)\n",
      "pb = Playback(fig,video)\n",
      "pb.start()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Tracking data:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Tracking data is stored as positions in the 4D Matrix, the fourth dimension specifies the time (frame) at which an objkect was tracked. Link between video data and position data is established using a **MultiTag** entity. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# get the tag linking tracking and video data\n",
      "tag = [t for t in b.multi_tags if t.name == \"tracking\"][0]\n",
      "\n",
      "fig = plt.figure(facecolor='white', figsize=(1024 / 90, 768 / 90), dpi=90)\n",
      "pb = Playback(fig, video, tracking_tag=tag)\n",
      "pb.start()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'video' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-4-7bec3dd06d10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfacecolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'white'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1024\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m90\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m768\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m90\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m90\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mpb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPlayback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracking_tag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: name 'video' is not defined"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Addtional Information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "During tracking additional information, i.e. the fish's orientation, is gathered. For each position there is also an orientation. This information is stored as a **Feature** of the tracking. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig = plt.figure(facecolor='white', figsize=(1024 / 90, 768 / 90), dpi=90)\n",
      "pb = Playback(fig, video, tracking_tag=tag, show_orientation=True)\n",
      "pb.start()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nix_file.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}